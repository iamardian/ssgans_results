{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semi_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamardian/ssgans_results/blob/main/semi_gan_ec-gan_d-digikala_p-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVzghhQznhMw",
        "outputId": "39362174-e8ea-47f2-bbc8-71a4160dc169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "746 / 852 * 100 = 87.55868544600939 \n",
            "\n",
            "======== Epoch 37 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 37 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "744 / 852 * 100 = 87.32394366197182 \n",
            "\n",
            "======== Epoch 38 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 38 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "757 / 852 * 100 = 88.84976525821597 \n",
            "\n",
            "======== Epoch 39 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 39 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "722 / 852 * 100 = 84.74178403755869 \n",
            "\n",
            "======== Epoch 40 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 40 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "745 / 852 * 100 = 87.44131455399061 \n",
            "\n",
            "======== Epoch 41 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 41 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "747 / 852 * 100 = 87.67605633802818 \n",
            "\n",
            "======== Epoch 42 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 42 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "748 / 852 * 100 = 87.79342723004694 \n",
            "\n",
            "======== Epoch 43 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 43 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "756 / 852 * 100 = 88.73239436619718 \n",
            "\n",
            "======== Epoch 44 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 44 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "737 / 852 * 100 = 86.50234741784037 \n",
            "\n",
            "======== Epoch 45 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 45 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "688 / 852 * 100 = 80.75117370892019 \n",
            "\n",
            "======== Epoch 46 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 46 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "753 / 852 * 100 = 88.38028169014085 \n",
            "\n",
            "======== Epoch 47 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 47 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "705 / 852 * 100 = 82.74647887323944 \n",
            "\n",
            "======== Epoch 48 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 48 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "747 / 852 * 100 = 87.67605633802818 \n",
            "\n",
            "======== Epoch 49 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 49 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "745 / 852 * 100 = 87.44131455399061 \n",
            "\n",
            "======== Epoch 50 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 50 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "631 / 852 * 100 = 74.06103286384976 \n",
            "\n",
            "======== Epoch 51 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 51 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "644 / 852 * 100 = 75.5868544600939 \n",
            "\n",
            "======== Epoch 52 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 52 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "537 / 852 * 100 = 63.02816901408451 \n",
            "\n",
            "======== Epoch 53 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 53 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "585 / 852 * 100 = 68.66197183098592 \n",
            "\n",
            "======== Epoch 54 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 54 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "721 / 852 * 100 = 84.6244131455399 \n",
            "\n",
            "======== Epoch 55 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 55 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "719 / 852 * 100 = 84.38967136150235 \n",
            "\n",
            "======== Epoch 56 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 56 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "498 / 852 * 100 = 58.45070422535211 \n",
            "\n",
            "======== Epoch 57 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 57 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "462 / 852 * 100 = 54.22535211267606 \n",
            "\n",
            "======== Epoch 58 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 58 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "466 / 852 * 100 = 54.694835680751176 \n",
            "\n",
            "======== Epoch 59 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 59 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "339 / 852 * 100 = 39.7887323943662 \n",
            "\n",
            "======== Epoch 60 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 60 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "350 / 852 * 100 = 41.07981220657277 \n",
            "\n",
            "======== Epoch 61 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 61 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "499 / 852 * 100 = 58.56807511737089 \n",
            "\n",
            "======== Epoch 62 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 62 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "614 / 852 * 100 = 72.06572769953051 \n",
            "\n",
            "======== Epoch 63 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 63 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "625 / 852 * 100 = 73.35680751173709 \n",
            "\n",
            "======== Epoch 64 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 64 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "616 / 852 * 100 = 72.30046948356808 \n",
            "\n",
            "======== Epoch 65 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 65 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "612 / 852 * 100 = 71.83098591549296 \n",
            "\n",
            "======== Epoch 66 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 66 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "606 / 852 * 100 = 71.12676056338029 \n",
            "\n",
            "======== Epoch 67 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 67 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "525 / 852 * 100 = 61.61971830985915 \n",
            "\n",
            "======== Epoch 68 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 68 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "589 / 852 * 100 = 69.13145539906104 \n",
            "\n",
            "======== Epoch 69 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 69 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "589 / 852 * 100 = 69.13145539906104 \n",
            "\n",
            "======== Epoch 70 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 70 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "584 / 852 * 100 = 68.54460093896714 \n",
            "\n",
            "======== Epoch 71 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 71 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "584 / 852 * 100 = 68.54460093896714 \n",
            "\n",
            "======== Epoch 72 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 72 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "513 / 852 * 100 = 60.2112676056338 \n",
            "\n",
            "======== Epoch 73 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 73 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "598 / 852 * 100 = 70.18779342723005 \n",
            "\n",
            "======== Epoch 74 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 74 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "548 / 852 * 100 = 64.31924882629107 \n",
            "\n",
            "======== Epoch 75 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 75 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "529 / 852 * 100 = 62.08920187793427 \n",
            "\n",
            "======== Epoch 76 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 76 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "482 / 852 * 100 = 56.57276995305164 \n",
            "\n",
            "======== Epoch 77 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 77 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "336 / 852 * 100 = 39.436619718309856 \n",
            "\n",
            "======== Epoch 78 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 78 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "342 / 852 * 100 = 40.140845070422536 \n",
            "\n",
            "======== Epoch 79 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 79 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "300 / 852 * 100 = 35.2112676056338 \n",
            "\n",
            "======== Epoch 80 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 80 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "327 / 852 * 100 = 38.38028169014084 \n",
            "\n",
            "======== Epoch 81 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 81 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "501 / 852 * 100 = 58.80281690140845 \n",
            "\n",
            "======== Epoch 82 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 82 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "507 / 852 * 100 = 59.50704225352113 \n",
            "\n",
            "======== Epoch 83 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 83 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "533 / 852 * 100 = 62.558685446009385 \n",
            "\n",
            "======== Epoch 84 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 84 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "546 / 852 * 100 = 64.08450704225352 \n",
            "\n",
            "======== Epoch 85 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 85 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "545 / 852 * 100 = 63.96713615023474 \n",
            "\n",
            "======== Epoch 86 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 86 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "542 / 852 * 100 = 63.6150234741784 \n",
            "\n",
            "======== Epoch 87 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 87 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "547 / 852 * 100 = 64.2018779342723 \n",
            "\n",
            "======== Epoch 88 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 88 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "545 / 852 * 100 = 63.96713615023474 \n",
            "\n",
            "======== Epoch 89 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 89 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "382 / 852 * 100 = 44.835680751173705 \n",
            "\n",
            "======== Epoch 90 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 90 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "371 / 852 * 100 = 43.544600938967136 \n",
            "\n",
            "======== Epoch 91 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 91 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "90     91  41.901408\n",
            "357 / 852 * 100 = 41.901408450704224 \n",
            "\n",
            "======== Epoch 92 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 92 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "90     91  41.901408\n",
            "91     92  64.319249\n",
            "548 / 852 * 100 = 64.31924882629107 \n",
            "\n",
            "======== Epoch 93 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 93 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "90     91  41.901408\n",
            "91     92  64.319249\n",
            "92     93  63.145540\n",
            "538 / 852 * 100 = 63.14553990610329 \n",
            "\n",
            "======== Epoch 94 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 94 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "90     91  41.901408\n",
            "91     92  64.319249\n",
            "92     93  63.145540\n",
            "93     94  63.262911\n",
            "539 / 852 * 100 = 63.262910798122064 \n",
            "\n",
            "======== Epoch 95 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 95 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "90     91  41.901408\n",
            "91     92  64.319249\n",
            "92     93  63.145540\n",
            "93     94  63.262911\n",
            "94     95  64.319249\n",
            "548 / 852 * 100 = 64.31924882629107 \n",
            "\n",
            "======== Epoch 96 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 96 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "90     91  41.901408\n",
            "91     92  64.319249\n",
            "92     93  63.145540\n",
            "93     94  63.262911\n",
            "94     95  64.319249\n",
            "95     96  80.516432\n",
            "686 / 852 * 100 = 80.51643192488262 \n",
            "\n",
            "======== Epoch 97 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 97 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "90     91  41.901408\n",
            "91     92  64.319249\n",
            "92     93  63.145540\n",
            "93     94  63.262911\n",
            "94     95  64.319249\n",
            "95     96  80.516432\n",
            "96     97  82.042254\n",
            "699 / 852 * 100 = 82.04225352112677 \n",
            "\n",
            "======== Epoch 98 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 98 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "90     91  41.901408\n",
            "91     92  64.319249\n",
            "92     93  63.145540\n",
            "93     94  63.262911\n",
            "94     95  64.319249\n",
            "95     96  80.516432\n",
            "96     97  82.042254\n",
            "97     98  82.746479\n",
            "705 / 852 * 100 = 82.74647887323944 \n",
            "\n",
            "======== Epoch 99 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 99 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "90     91  41.901408\n",
            "91     92  64.319249\n",
            "92     93  63.145540\n",
            "93     94  63.262911\n",
            "94     95  64.319249\n",
            "95     96  80.516432\n",
            "96     97  82.042254\n",
            "97     98  82.746479\n",
            "98     99  74.882629\n",
            "638 / 852 * 100 = 74.88262910798123 \n",
            "\n",
            "======== Epoch 100 / 100 ========\n",
            "Training...\n",
            "./semi_supervised_learning_with_gan/ecgan_parsbert.py:348: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(logits)\n",
            "Epoch 100 Complete\n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "90     91  41.901408\n",
            "91     92  64.319249\n",
            "92     93  63.145540\n",
            "93     94  63.262911\n",
            "94     95  64.319249\n",
            "95     96  80.516432\n",
            "96     97  82.042254\n",
            "97     98  82.746479\n",
            "98     99  74.882629\n",
            "99    100  77.934272\n",
            "664 / 852 * 100 = 77.93427230046949 \n",
            "    epoch        acc\n",
            "0       1  32.511737\n",
            "1       2  32.511737\n",
            "2       3  32.511737\n",
            "3       4  51.173709\n",
            "4       5  53.990610\n",
            "5       6  84.741784\n",
            "6       7  82.511737\n",
            "7       8  84.624413\n",
            "8       9  85.798122\n",
            "9      10  85.563380\n",
            "10     11  85.211268\n",
            "11     12  84.976526\n",
            "12     13  85.211268\n",
            "13     14  86.267606\n",
            "14     15  87.676056\n",
            "15     16  86.971831\n",
            "16     17  87.441315\n",
            "17     18  86.267606\n",
            "18     19  87.558685\n",
            "19     20  87.089202\n",
            "20     21  87.676056\n",
            "21     22  87.089202\n",
            "22     23  87.089202\n",
            "23     24  87.206573\n",
            "24     25  87.323944\n",
            "25     26  87.323944\n",
            "26     27  86.150235\n",
            "27     28  87.089202\n",
            "28     29  86.619718\n",
            "29     30  87.206573\n",
            "30     31  86.737089\n",
            "31     32  86.384977\n",
            "32     33  70.422535\n",
            "33     34  84.624413\n",
            "34     35  86.854460\n",
            "35     36  87.558685\n",
            "36     37  87.323944\n",
            "37     38  88.849765\n",
            "38     39  84.741784\n",
            "39     40  87.441315\n",
            "40     41  87.676056\n",
            "41     42  87.793427\n",
            "42     43  88.732394\n",
            "43     44  86.502347\n",
            "44     45  80.751174\n",
            "45     46  88.380282\n",
            "46     47  82.746479\n",
            "47     48  87.676056\n",
            "48     49  87.441315\n",
            "49     50  74.061033\n",
            "50     51  75.586854\n",
            "51     52  63.028169\n",
            "52     53  68.661972\n",
            "53     54  84.624413\n",
            "54     55  84.389671\n",
            "55     56  58.450704\n",
            "56     57  54.225352\n",
            "57     58  54.694836\n",
            "58     59  39.788732\n",
            "59     60  41.079812\n",
            "60     61  58.568075\n",
            "61     62  72.065728\n",
            "62     63  73.356808\n",
            "63     64  72.300469\n",
            "64     65  71.830986\n",
            "65     66  71.126761\n",
            "66     67  61.619718\n",
            "67     68  69.131455\n",
            "68     69  69.131455\n",
            "69     70  68.544601\n",
            "70     71  68.544601\n",
            "71     72  60.211268\n",
            "72     73  70.187793\n",
            "73     74  64.319249\n",
            "74     75  62.089202\n",
            "75     76  56.572770\n",
            "76     77  39.436620\n",
            "77     78  40.140845\n",
            "78     79  35.211268\n",
            "79     80  38.380282\n",
            "80     81  58.802817\n",
            "81     82  59.507042\n",
            "82     83  62.558685\n",
            "83     84  64.084507\n",
            "84     85  63.967136\n",
            "85     86  63.615023\n",
            "86     87  64.201878\n",
            "87     88  63.967136\n",
            "88     89  44.835681\n",
            "89     90  43.544601\n",
            "90     91  41.901408\n",
            "91     92  64.319249\n",
            "92     93  63.145540\n",
            "93     94  63.262911\n",
            "94     95  64.319249\n",
            "95     96  80.516432\n",
            "96     97  82.042254\n",
            "97     98  82.746479\n",
            "98     99  74.882629\n",
            "99    100  77.934272\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.3.2\n",
        "!rm -r ./semi_supervised_learning_with_gan ;git clone https://github.com/iamardian/semi_supervised_learning_with_gan.git\n",
        "# !python ./semi_supervised_learning_with_gan/ssgan_parsbert.py\n",
        "!python ./semi_supervised_learning_with_gan/ecgan_parsbert.py -d digikalamag -p 0.02"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MxznXs1WoSc-"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}