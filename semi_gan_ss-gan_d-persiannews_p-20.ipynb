{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semi_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamardian/ssgans_results/blob/main/semi_gan_ss-gan_d-persiannews_p-20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVzghhQznhMw",
        "outputId": "b09a50df-9676-41b8-8941-a148b5e4661f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.3.2\n",
            "  Downloading transformers-4.3.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 6.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 28.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (2022.6.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (3.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (4.11.4)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 69.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.2) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.2) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.2) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (2022.5.18.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=89ef808c8a9636393f083ea59ebb24392ea0bfbf1c61d1859b34fa11cca0c983\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.3.2\n",
            "rm: cannot remove './semi_supervised_learning_with_gan': No such file or directory\n",
            "Cloning into 'semi_supervised_learning_with_gan'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 46 (delta 23), reused 35 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (46/46), done.\n",
            "Dataset : persiannews \n",
            "Percentage : 0.2\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Cloning into 'persiannews'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n",
            "./persiannews/train.csv\n",
            "./persiannews/test.csv\n",
            "Downloading: 100% 440/440 [00:00<00:00, 423kB/s]\n",
            "Downloading: 100% 654M/654M [00:11<00:00, 56.5MB/s]\n",
            "Downloading: 100% 1.20M/1.20M [00:00<00:00, 3.16MB/s]\n",
            "[0, 1, 2, 3, 4, 5, 6, 7]\n",
            "train_examples :  13314\n",
            "labeled_data_const :  2662\n",
            "labeled_examples :  2662\n",
            "unlabeled_examples :  10652\n",
            "\n",
            "======== Epoch 1 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:20.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:39.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:00.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:22.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:44.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:07.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:29.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:51.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:13.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:35.\n",
            "  Batch   110  of    250.    Elapsed: 0:03:57.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:19.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:41.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:03.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:26.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:48.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:10.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:32.\n",
            "  Batch   190  of    250.    Elapsed: 0:06:54.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:16.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:38.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:01.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:23.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:45.\n",
            "\n",
            "  Average training loss generetor: 0.687\n",
            "  Average training loss discriminator: 1.213\n",
            "  Training epcoh took: 0:09:06\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.953\n",
            "   epoch       acc\n",
            "0      1  0.953163\n",
            "  Test Loss: 0.159\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 2 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:42.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:04.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:26.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:17.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:39.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:01.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:23.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:45.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:52.\n",
            "\n",
            "  Average training loss generetor: 0.706\n",
            "  Average training loss discriminator: 0.770\n",
            "  Training epcoh took: 0:09:13\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.954\n",
            "   epoch       acc\n",
            "0      1  0.953163\n",
            "1      2  0.953771\n",
            "  Test Loss: 0.217\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 3 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:45.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.701\n",
            "  Average training loss discriminator: 0.768\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.925\n",
            "   epoch       acc\n",
            "0      1  0.953163\n",
            "1      2  0.953771\n",
            "2      3  0.925182\n",
            "  Test Loss: 0.382\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 4 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:26.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:01.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:23.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:45.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.700\n",
            "  Average training loss discriminator: 0.753\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.953\n",
            "   epoch       acc\n",
            "0      1  0.953163\n",
            "1      2  0.953771\n",
            "2      3  0.925182\n",
            "3      4  0.952555\n",
            "  Test Loss: 0.203\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 5 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:47.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.699\n",
            "  Average training loss discriminator: 0.713\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.949\n",
            "   epoch       acc\n",
            "0      1  0.953163\n",
            "1      2  0.953771\n",
            "2      3  0.925182\n",
            "3      4  0.952555\n",
            "4      5  0.948905\n",
            "  Test Loss: 0.289\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 6 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.700\n",
            "  Average training loss discriminator: 0.717\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.954\n",
            "   epoch       acc\n",
            "0      1  0.953163\n",
            "1      2  0.953771\n",
            "2      3  0.925182\n",
            "3      4  0.952555\n",
            "4      5  0.948905\n",
            "5      6  0.954380\n",
            "  Test Loss: 0.228\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 7 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:04.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:26.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:39.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:01.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:23.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:45.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:52.\n",
            "\n",
            "  Average training loss generetor: 0.699\n",
            "  Average training loss discriminator: 0.716\n",
            "  Training epcoh took: 0:09:13\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.965\n",
            "   epoch       acc\n",
            "0      1  0.953163\n",
            "1      2  0.953771\n",
            "2      3  0.925182\n",
            "3      4  0.952555\n",
            "4      5  0.948905\n",
            "5      6  0.954380\n",
            "6      7  0.964720\n",
            "  Test Loss: 0.210\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 8 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:42.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:04.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:26.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:33.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:55.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:17.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:39.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:01.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:23.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:45.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:30.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:52.\n",
            "\n",
            "  Average training loss generetor: 0.699\n",
            "  Average training loss discriminator: 0.703\n",
            "  Training epcoh took: 0:09:13\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.962\n",
            "   epoch       acc\n",
            "0      1  0.953163\n",
            "1      2  0.953771\n",
            "2      3  0.925182\n",
            "3      4  0.952555\n",
            "4      5  0.948905\n",
            "5      6  0.954380\n",
            "6      7  0.964720\n",
            "7      8  0.962287\n",
            "  Test Loss: 0.233\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 9 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:26.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:01.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:23.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:45.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.699\n",
            "  Average training loss discriminator: 0.701\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.964\n",
            "   epoch       acc\n",
            "0      1  0.953163\n",
            "1      2  0.953771\n",
            "2      3  0.925182\n",
            "3      4  0.952555\n",
            "4      5  0.948905\n",
            "5      6  0.954380\n",
            "6      7  0.964720\n",
            "7      8  0.962287\n",
            "8      9  0.964112\n",
            "  Test Loss: 0.243\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 10 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:23.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:45.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.701\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.964\n",
            "   epoch       acc\n",
            "0      1  0.953163\n",
            "1      2  0.953771\n",
            "2      3  0.925182\n",
            "3      4  0.952555\n",
            "4      5  0.948905\n",
            "5      6  0.954380\n",
            "6      7  0.964720\n",
            "7      8  0.962287\n",
            "8      9  0.964112\n",
            "9     10  0.964112\n",
            "  Test Loss: 0.251\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 11 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.700\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.964\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "  Test Loss: 0.259\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 12 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:26.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:45.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.700\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.964\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "11     12  0.964112\n",
            "  Test Loss: 0.272\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 13 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.700\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.964\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "11     12  0.964112\n",
            "12     13  0.964112\n",
            "  Test Loss: 0.269\n",
            "  Test took: 0:00:12\n",
            "\n",
            "======== Epoch 14 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:47.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:06.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.699\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.963\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "11     12  0.964112\n",
            "12     13  0.964112\n",
            "13     14  0.962895\n",
            "  Test Loss: 0.280\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 15 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:26.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.697\n",
            "  Average training loss discriminator: 0.699\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.960\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "11     12  0.964112\n",
            "12     13  0.964112\n",
            "13     14  0.962895\n",
            "14     15  0.960462\n",
            "  Test Loss: 0.289\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 16 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:47.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.697\n",
            "  Average training loss discriminator: 0.699\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.962\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "11     12  0.964112\n",
            "12     13  0.964112\n",
            "13     14  0.962895\n",
            "14     15  0.960462\n",
            "15     16  0.962287\n",
            "  Test Loss: 0.295\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 17 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:06.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.697\n",
            "  Average training loss discriminator: 0.698\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.960\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "11     12  0.964112\n",
            "12     13  0.964112\n",
            "13     14  0.962895\n",
            "14     15  0.960462\n",
            "15     16  0.962287\n",
            "16     17  0.960462\n",
            "  Test Loss: 0.298\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 18 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:45.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:07.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.697\n",
            "  Average training loss discriminator: 0.698\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.963\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "11     12  0.964112\n",
            "12     13  0.964112\n",
            "13     14  0.962895\n",
            "14     15  0.960462\n",
            "15     16  0.962287\n",
            "16     17  0.960462\n",
            "17     18  0.962895\n",
            "  Test Loss: 0.296\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 19 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:47.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:06.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.697\n",
            "  Average training loss discriminator: 0.698\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.962\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "11     12  0.964112\n",
            "12     13  0.964112\n",
            "13     14  0.962895\n",
            "14     15  0.960462\n",
            "15     16  0.962287\n",
            "16     17  0.960462\n",
            "17     18  0.962895\n",
            "18     19  0.961679\n",
            "  Test Loss: 0.299\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 20 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:47.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:06.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.697\n",
            "  Average training loss discriminator: 0.697\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.960\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "11     12  0.964112\n",
            "12     13  0.964112\n",
            "13     14  0.962895\n",
            "14     15  0.960462\n",
            "15     16  0.962287\n",
            "16     17  0.960462\n",
            "17     18  0.962895\n",
            "18     19  0.961679\n",
            "19     20  0.960462\n",
            "  Test Loss: 0.303\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 21 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:47.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:06.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:29.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.696\n",
            "  Average training loss discriminator: 0.697\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.961\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "11     12  0.964112\n",
            "12     13  0.964112\n",
            "13     14  0.962895\n",
            "14     15  0.960462\n",
            "15     16  0.962287\n",
            "16     17  0.960462\n",
            "17     18  0.962895\n",
            "18     19  0.961679\n",
            "19     20  0.960462\n",
            "20     21  0.961071\n",
            "  Test Loss: 0.313\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 22 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:47.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:44.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:06.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:28.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:51.\n",
            "\n",
            "  Average training loss generetor: 0.696\n",
            "  Average training loss discriminator: 0.697\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.960\n",
            "    epoch       acc\n",
            "0       1  0.953163\n",
            "1       2  0.953771\n",
            "2       3  0.925182\n",
            "3       4  0.952555\n",
            "4       5  0.948905\n",
            "5       6  0.954380\n",
            "6       7  0.964720\n",
            "7       8  0.962287\n",
            "8       9  0.964112\n",
            "9      10  0.964112\n",
            "10     11  0.964112\n",
            "11     12  0.964112\n",
            "12     13  0.964112\n",
            "13     14  0.962895\n",
            "14     15  0.960462\n",
            "15     16  0.962287\n",
            "16     17  0.960462\n",
            "17     18  0.962895\n",
            "18     19  0.961679\n",
            "19     20  0.960462\n",
            "20     21  0.961071\n",
            "21     22  0.960462\n",
            "  Test Loss: 0.317\n",
            "  Test took: 0:00:12\n",
            "\n",
            "======== Epoch 23 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:44.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:06.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:28.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:51.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:13.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:35.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:57.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:19.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:41.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:03.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:25.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:48.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:10.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:32.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:54.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:16.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:38.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:00.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:22.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.3.2\n",
        "!rm -r ./semi_supervised_learning_with_gan ;git clone https://github.com/iamardian/semi_supervised_learning_with_gan.git\n",
        "!python ./semi_supervised_learning_with_gan/ssgan_parsbert.py -d persiannews -p 0.2\n",
        "# !python ecgan_parsbert.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MxznXs1WoSc-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}